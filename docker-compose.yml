services:
  # --- Core Infrastructure ---

  redis:
    image: redis:7-alpine
    container_name: brain-redis
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-stack
    restart: unless-stopped

  postgres:
    image: postgres:16-alpine
    container_name: brain-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-stack
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: brain-ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    healthcheck:
      test: [ "CMD", "ollama", "list" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-stack
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    container_name: brain-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks:
      - ai-stack
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: always
    ports:
      - "3000:8080"
    environment:
      # Użycie nazwy usługi wewnątrz sieci Docker
      - OPENAI_API_BASE_URL=http://brain-pipelines:9099
      - OPENAI_API_KEY=0p3n-w3bu!
    volumes:
      - ./data/open-webui:/app/backend/data
      - ./custom_pipelines:/app/pipelines
    networks:
      - ai-stack
    depends_on:
      - pipelines

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: brain-pipelines
    restart: always
    ports:
      - "9099:9099"
    environment:
      - PIPELINES_API_KEY=0p3n-w3bu!
      # KLUCZOWE: Włącza hot-reload w uvicorn
      - PIPELINES_ENV=development
      # Zapewnienie, że pip instaluje pakiety w miejscu dostępnym dla procesu
      - PIPELINES_REQUIREMENTS_PATH=/app/pipelines/requirements.txt
    volumes:
      # Mapowanie lokalnego katalogu z kodem
      - ./custom_pipelines:/app/pipelines
    networks:
      - ai-stack

  # --- Agent Services ---

  collector:
    build:
      context: ./modules/collector
      dockerfile: Dockerfile
    container_name: brain-collector
    volumes:
      - ${INBOX_PATH}:/inbox
      - ./shared:/shared
      - ./credentials.json:/app/credentials.json
      - ./token.json:/app/token.json
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-DEBUG}
      - REDIS_HOST=redis
      - INBOX_PATH=/inbox
      - GOOGLE_DRIVE_INBOX_ID=${GOOGLE_DRIVE_INBOX_ID}
      - GOOGLE_DRIVE_CREDENTIALS=/app/credentials.json
      - GOOGLE_DRIVE_TOKEN=/app/token.json
    command: sh -c "pip install -e /shared && python main.py"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-stack
    restart: unless-stopped

  refinery:
    build:
      context: ./modules/refinery
      dockerfile: Dockerfile
    container_name: brain-refinery
    volumes:
      - ${OBSIDIAN_VAULT_PATH}:/vault
      - ./shared:/shared
      - ./scripts:/scripts
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - REDIS_HOST=redis
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=llama3.2
      - OBSIDIAN_VAULT_PATH=/vault
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
    command: sh -c "pip install -e /shared && python main.py"
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - ai-stack
    restart: unless-stopped

  finance:
    build:
      context: ./modules/finance
      dockerfile: Dockerfile
    container_name: brain-finance
    volumes:
      - ${INBOX_PATH}:/inbox
      - ./data/product_cache.json:/app/data/product_cache.json
      - ./shared:/shared
      - ./gcp_key.json:/app/gcp_key.json
    command: sh -c "pip install -e /shared && python main.py"
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - REDIS_HOST=redis
      - INBOX_PATH=/inbox
      - OLLAMA_HOST=http://ollama:11434
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp_key.json
      - AI_PROVIDER=${AI_PROVIDER}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OCR_PROVIDER=${OCR_PROVIDER}
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - ai-stack
    restart: unless-stopped

networks:
  ai-stack:
    driver: bridge

volumes:
  open-webui:
